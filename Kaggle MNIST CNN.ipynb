{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C:/Users/Matt/Desktop/School/Personal_Study/Deep_Learning/Udemy_Complete_Guide_to_TensorFlow/Kaggle_MNIST_Data/train.csv\")\n",
    "test = pd.read_csv(\"C:/Users/Matt/Desktop/School/Personal_Study/Deep_Learning/Udemy_Complete_Guide_to_TensorFlow/Kaggle_MNIST_Data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train.loc[:, train.columns != 'label']\n",
    "y = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.as_matrix() \n",
    "y_train = y_train.as_matrix() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val = X_val.as_matrix() \n",
    "y_val = y_val.as_matrix() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Used to one-hot encode the 10 labels\n",
    "def one_hot_encode_labels(vector, total_labels=10):\n",
    "    # extract number of rows/observations\n",
    "    number_of_obs = len(vector)\n",
    "    # initialize matrix that will represent our one-hot encoding\n",
    "    output = np.zeros((number_of_obs,total_labels))\n",
    "    # for each row, set the column to 1 based on the label\n",
    "    output[range(number_of_obs), vector] = 1\n",
    "    # return final matrix\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MNIST_Data_Prep():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.i = 0\n",
    "        \n",
    "        # Initialize some empty variables for later on\n",
    "        self.training_images = None\n",
    "        self.training_labels = None\n",
    "        \n",
    "        self.val_images = None\n",
    "        self.val_labels = None\n",
    "        \n",
    "        self.test_images = None\n",
    "        \n",
    "    def set_up_images(self):\n",
    "        \n",
    "        print(\"Setting Up Training Images and Labels\")\n",
    "        \n",
    "        # define training images\n",
    "        self.training_images = X_train\n",
    "        train_len = len(self.training_images)\n",
    "        \n",
    "        # Reshapes and normalizes training images\n",
    "        # NOTE: the max value in the images is 255, so that is where the 255 comes from, it's the 'normalizing' step\n",
    "        self.training_images = self.training_images.reshape(train_len,28,28,1).transpose(0,1,2,3)/255\n",
    "        # One Hot Encodes the training labels\n",
    "        self.training_labels = one_hot_encode_labels(y_train)\n",
    "        \n",
    "        print(\"Setting Up Validation Images and Labels\")\n",
    "        \n",
    "        # define test images\n",
    "        self.val_images = X_val\n",
    "        val_len = len(self.val_images)\n",
    "        \n",
    "        # Reshapes and normalizes test images\n",
    "        # NOTE: the max value in the images is 255, so that is where the 255 comes from, it's the 'normalizing' step\n",
    "        self.val_images = self.val_images.reshape(val_len,28,28,1).transpose(0,1,2,3)/255\n",
    "        # One Hot Encodes the training labels\n",
    "        self.val_labels = one_hot_encode_labels(y_val)\n",
    "        \n",
    "        print(\"Setting Up Test Images and Labels\")\n",
    "        \n",
    "        # define test images\n",
    "        self.test_images = X_test\n",
    "        test_len = len(self.test_images)\n",
    "        \n",
    "        # Reshapes and normalizes test images\n",
    "        # NOTE: the max value in the images is 255, so that is where the 255 comes from, it's the 'normalizing' step\n",
    "        self.test_images = self.test_images.reshape(test_len,28,28,1).transpose(0,1,2,3)/255\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        # self.i:self.i+batch_size - means grab training images from self.i up to self.i+batch_size\n",
    "        #x = self.training_images[self.i:self.i+batch_size].reshape(batch_size,28,28,1)\n",
    "        x = self.training_images[self.i:self.i+batch_size]\n",
    "        y = self.training_labels[self.i:self.i+batch_size]\n",
    "        self.i = (self.i + batch_size) % len(self.training_images)     \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### SETTING UP PLACEHOLDERS FOR OUR TRAINING DATA\n",
    "# None - because this is dictated by the batch size; 28, 28 - represents 28x28 pixels; 1 - # of color channels\n",
    "# i.e. [images, height, width, channels]\n",
    "x = tf.placeholder(tf.float32,shape=[None,28,28,1])\n",
    "y_true = tf.placeholder(tf.float32,shape=[None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FOR DROPOUT, % OF NEURONS WE WANT TO KEEP\n",
    "hold_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shape depends on the size of our images and size of our tensors\n",
    "\n",
    "def init_weights(shape):\n",
    "    # tf.truncated_normal = Outputs random values from a truncated normal distribution.\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def convolutional_layer(input_x, shape):\n",
    "    # initalize the weights, passing along the shape\n",
    "    W = init_weights(shape)\n",
    "    # initalize the biases, passing along the number of channels, which is located in position 3 in list 'shape'\n",
    "    b = init_weights([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)\n",
    "\n",
    "# this is just a regular MLP layer, this doesn't flatten the data, only runs a MLP layer on a flattened layer\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convo_1 = convolutional_layer(x,shape=[4,4,1,28])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convo_2 = convolutional_layer(convo_1_pooling,shape=[4,4,28,64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convo_2_flat = tf.reshape(convo_2_pooling,[-1,7*7*64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "trainer = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Up Training Images and Labels\n",
      "Setting Up Validation Images and Labels\n",
      "Setting Up Test Images and Labels\n"
     ]
    }
   ],
   "source": [
    "ch = MNIST_Data_Prep()\n",
    "ch.set_up_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a saver.\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP: 0\n",
      "0.148196\n",
      "\n",
      "\n",
      "STEP: 100\n",
      "0.957431\n",
      "\n",
      "\n",
      "STEP: 200\n",
      "0.970851\n",
      "\n",
      "\n",
      "STEP: 300\n",
      "0.977417\n",
      "\n",
      "\n",
      "STEP: 400\n",
      "0.976551\n",
      "\n",
      "\n",
      "STEP: 500\n",
      "0.982035\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(501):\n",
    "        \n",
    "        batch = ch.next_batch(100)\n",
    "        \n",
    "        # remember that next_batch returns a tuple (x,y) where x is the training examples and y is the labels\n",
    "        # also reminder that hold_prob we created as a placeholder for our dropout rate, here we define that we want our\n",
    "        # dropout rate to be 50%\n",
    "        sess.run(trainer,feed_dict={x:batch[0],y_true:batch[1],hold_prob:0.5})\n",
    "        \n",
    "        # Save our model for inference later on\n",
    "        saver.save(sess, 'C:/Users/Matt/Desktop/School/Personal_Study/Deep_Learning/Udemy_Complete_Guide_to_TensorFlow/Kaggle_MNIST_Model/my_mnist_cnn')\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            \n",
    "            # print what step we're on\n",
    "            print(\"STEP: {}\".format(i))\n",
    "            \n",
    "            # Now we want to also print our TEST ACCURACY score\n",
    "            # to do this we will set up the calculations then run another session that feeds in the test\n",
    "            # images and test labels\n",
    "            # remember that y_pred is part of 'train' which we defined when we defined our Convolutional Network Architecture\n",
    "            \n",
    "            # if the index of the highest probability matches the index of the true value (i.e. the max value being 1)\n",
    "            # then we return boolean TRUE, otherwise we return boolean FALSE\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "            \n",
    "            # tf.reduce_mean is basically just the tenforflow function for saying \"calculate the mean\"\n",
    "            # tf.cast is used to cast the boolean values TRUE & FALSE to binary float values 1.0 and 0.0\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "            \n",
    "            # hold_prob = 1 because we don't want to hold out any neurons during inference\n",
    "            print(sess.run(acc,feed_dict={x:ch.val_images,y_true:ch.val_labels,hold_prob:1.0}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:/Users/Matt/Desktop/School/Personal_Study/Deep_Learning/Udemy_Complete_Guide_to_TensorFlow/Kaggle_MNIST_Model/my_mnist_cnn\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    saver.restore(session, 'C:/Users/Matt/Desktop/School/Personal_Study/Deep_Learning/Udemy_Complete_Guide_to_TensorFlow/Kaggle_MNIST_Model/my_mnist_cnn')\n",
    "    prediction = session.run(tf.argmax(y_pred, 1), feed_dict={x:ch.test_images,hold_prob:1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = np.vstack((np.arange(1,28001),prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(data=final.transpose(),columns=['ImageId','Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv('C:/Users/Matt/Desktop/School/Personal_Study/Deep_Learning/Udemy_Complete_Guide_to_TensorFlow/Kaggle_MNIST_Preds/mjy_mnist_preds_cnn_v1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
